{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CreditScoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>seniority</th>\n",
       "      <th>home</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>records</th>\n",
       "      <th>job</th>\n",
       "      <th>expenses</th>\n",
       "      <th>income</th>\n",
       "      <th>assets</th>\n",
       "      <th>debt</th>\n",
       "      <th>amount</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>182</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status  seniority  home  time  age  marital  records  job  expenses  \\\n",
       "0       1          9     1    60   30        2        1    3        73   \n",
       "1       1         17     1    60   58        3        1    1        48   \n",
       "2       2         10     2    36   46        2        2    3        90   \n",
       "3       1          0     1    60   24        1        1    1        63   \n",
       "4       1          0     1    36   26        1        1    1        46   \n",
       "\n",
       "   income  assets  debt  amount  price  \n",
       "0     129       0     0     800    846  \n",
       "1     131       0     0    1000   1658  \n",
       "2     200    3000     0    2000   2985  \n",
       "3     182    2500     0     900   1325  \n",
       "4     107       0     0     310    910  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data cleaning\n",
    "df.columns = df.columns.str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>seniority</th>\n",
       "      <th>home</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>records</th>\n",
       "      <th>job</th>\n",
       "      <th>expenses</th>\n",
       "      <th>income</th>\n",
       "      <th>assets</th>\n",
       "      <th>debt</th>\n",
       "      <th>amount</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ok</td>\n",
       "      <td>9</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>freelance</td>\n",
       "      <td>73</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok</td>\n",
       "      <td>17</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>widow</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>48</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>default</td>\n",
       "      <td>10</td>\n",
       "      <td>owner</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>married</td>\n",
       "      <td>yes</td>\n",
       "      <td>freelance</td>\n",
       "      <td>90</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ok</td>\n",
       "      <td>0</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>single</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>63</td>\n",
       "      <td>182</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ok</td>\n",
       "      <td>0</td>\n",
       "      <td>rent</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>single</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    status  seniority   home  time  age  marital records        job  expenses  \\\n",
       "0       ok          9   rent    60   30  married      no  freelance        73   \n",
       "1       ok         17   rent    60   58    widow      no      fixed        48   \n",
       "2  default         10  owner    36   46  married     yes  freelance        90   \n",
       "3       ok          0   rent    60   24   single      no      fixed        63   \n",
       "4       ok          0   rent    36   26   single      no      fixed        46   \n",
       "\n",
       "   income  assets  debt  amount  price  \n",
       "0     129       0     0     800    846  \n",
       "1     131       0     0    1000   1658  \n",
       "2     200    3000     0    2000   2985  \n",
       "3     182    2500     0     900   1325  \n",
       "4     107       0     0     310    910  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transalting numerical values ot categorical\n",
    "status_values = {\n",
    "    1: 'ok',\n",
    "    2: 'default',\n",
    "    3: 'unk'\n",
    "}\n",
    "\n",
    "home_values = {\n",
    "    1: 'rent',\n",
    "    2: 'owner',\n",
    "    3: 'private',\n",
    "    4: 'ignore',\n",
    "    5: 'parents',\n",
    "    6: 'other',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "marital_values = {\n",
    "    1: 'single',\n",
    "    2: 'married',\n",
    "    3: 'widow',\n",
    "    4: 'separated',\n",
    "    5: 'divorced',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "records_values = {\n",
    "    1: 'no',\n",
    "    2: 'yes',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "job_values = {\n",
    "    1: 'fixed',\n",
    "    2: 'partime',\n",
    "    3: 'freelance',\n",
    "    4: 'others',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.status = df.status.map(status_values)\n",
    "df.home = df.home.map(home_values)\n",
    "df.marital = df.marital.map(marital_values)\n",
    "df.records = df.records.map(records_values)\n",
    "df.job = df.job.map(job_values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seniority</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>expenses</th>\n",
       "      <th>income</th>\n",
       "      <th>assets</th>\n",
       "      <th>debt</th>\n",
       "      <th>amount</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4455.0</td>\n",
       "      <td>4455.0</td>\n",
       "      <td>4455.0</td>\n",
       "      <td>4455.0</td>\n",
       "      <td>4421.0</td>\n",
       "      <td>4408.0</td>\n",
       "      <td>4437.0</td>\n",
       "      <td>4455.0</td>\n",
       "      <td>4455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5403.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>1463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>11573.0</td>\n",
       "      <td>1246.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>628.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>1692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>959.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>11140.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       seniority    time     age  expenses  income    assets     debt  amount  \\\n",
       "count     4455.0  4455.0  4455.0    4455.0  4421.0    4408.0   4437.0  4455.0   \n",
       "mean         8.0    46.0    37.0      56.0   131.0    5403.0    343.0  1039.0   \n",
       "std          8.0    15.0    11.0      20.0    86.0   11573.0   1246.0   475.0   \n",
       "min          0.0     6.0    18.0      35.0     0.0       0.0      0.0   100.0   \n",
       "25%          2.0    36.0    28.0      35.0    80.0       0.0      0.0   700.0   \n",
       "50%          5.0    48.0    36.0      51.0   120.0    3000.0      0.0  1000.0   \n",
       "75%         12.0    60.0    45.0      72.0   165.0    6000.0      0.0  1300.0   \n",
       "max         48.0    72.0    68.0     180.0   959.0  300000.0  30000.0  5000.0   \n",
       "\n",
       "         price  \n",
       "count   4455.0  \n",
       "mean    1463.0  \n",
       "std      628.0  \n",
       "min      105.0  \n",
       "25%     1118.0  \n",
       "50%     1400.0  \n",
       "75%     1692.0  \n",
       "max    11140.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset preparation\n",
    "# Summery statistics for each column (numerical values only)\n",
    "# missing values are encoded with a suspicious value 99999999 to we convert it to NAN\n",
    "for c in ['income', 'assets', 'debt']:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=np.nan)\n",
    "df.describe().round() #to the nearst integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ok         3200\n",
       "default    1254\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc 0.7017132266649385\n",
      "val auc 0.6876073869887143\n",
      "   1 -> 0.613\n",
      "   2 -> 0.688\n",
      "   3 -> 0.763\n",
      "   4 -> 0.779\n",
      "   5 -> 0.784\n",
      "   6 -> 0.777\n",
      "  10 -> 0.712\n",
      "  15 -> 0.672\n",
      "  20 -> 0.669\n",
      "None -> 0.674\n",
      "depth: 4\n",
      "1 -> 0.779\n",
      "5 -> 0.779\n",
      "10 -> 0.774\n",
      "15 -> 0.771\n",
      "20 -> 0.784\n",
      "50 -> 0.778\n",
      "100 -> 0.767\n",
      "200 -> 0.765\n",
      "\n",
      "depth: 5\n",
      "1 -> 0.783\n",
      "5 -> 0.787\n",
      "10 -> 0.783\n",
      "15 -> 0.780\n",
      "20 -> 0.785\n",
      "50 -> 0.789\n",
      "100 -> 0.786\n",
      "200 -> 0.778\n",
      "\n",
      "depth: 6\n",
      "1 -> 0.774\n",
      "5 -> 0.785\n",
      "10 -> 0.792\n",
      "15 -> 0.795\n",
      "20 -> 0.800\n",
      "50 -> 0.793\n",
      "100 -> 0.793\n",
      "200 -> 0.789\n",
      "\n",
      "train auc 0.8429263976804766\n",
      "val auc 0.7990426334070879\n",
      "10 -> 0.802\n",
      "20 -> 0.826\n",
      "30 -> 0.826\n",
      "40 -> 0.827\n",
      "50 -> 0.832\n",
      "60 -> 0.832\n",
      "70 -> 0.830\n",
      "80 -> 0.832\n",
      "90 -> 0.832\n",
      "100 -> 0.829\n",
      "110 -> 0.830\n",
      "120 -> 0.831\n",
      "130 -> 0.832\n",
      "140 -> 0.833\n",
      "150 -> 0.834\n",
      "160 -> 0.834\n",
      "170 -> 0.833\n",
      "180 -> 0.833\n",
      "190 -> 0.834\n",
      "200 -> 0.834\n",
      "depth: 5\n",
      "10 -> 0.817\n",
      "20 -> 0.822\n",
      "30 -> 0.822\n",
      "40 -> 0.825\n",
      "50 -> 0.829\n",
      "60 -> 0.831\n",
      "70 -> 0.832\n",
      "80 -> 0.831\n",
      "90 -> 0.831\n",
      "100 -> 0.831\n",
      "110 -> 0.831\n",
      "120 -> 0.830\n",
      "130 -> 0.830\n",
      "140 -> 0.830\n",
      "150 -> 0.829\n",
      "160 -> 0.830\n",
      "170 -> 0.830\n",
      "180 -> 0.830\n",
      "190 -> 0.831\n",
      "200 -> 0.831\n",
      "\n",
      "depth: 10\n",
      "10 -> 0.809\n",
      "20 -> 0.824\n",
      "30 -> 0.826\n",
      "40 -> 0.835\n",
      "50 -> 0.839\n",
      "60 -> 0.841\n",
      "70 -> 0.842\n",
      "80 -> 0.843\n",
      "90 -> 0.843\n",
      "100 -> 0.841\n",
      "110 -> 0.841\n",
      "120 -> 0.841\n",
      "130 -> 0.842\n",
      "140 -> 0.842\n",
      "150 -> 0.842\n",
      "160 -> 0.843\n",
      "170 -> 0.842\n",
      "180 -> 0.841\n",
      "190 -> 0.840\n",
      "200 -> 0.840\n",
      "\n",
      "depth: 20\n",
      "10 -> 0.803\n",
      "20 -> 0.827\n",
      "30 -> 0.834\n",
      "40 -> 0.835\n",
      "50 -> 0.834\n",
      "60 -> 0.831\n",
      "70 -> 0.831\n",
      "80 -> 0.832\n",
      "90 -> 0.832\n",
      "100 -> 0.833\n",
      "110 -> 0.833\n",
      "120 -> 0.833\n",
      "130 -> 0.834\n",
      "140 -> 0.835\n",
      "150 -> 0.836\n",
      "160 -> 0.835\n",
      "170 -> 0.836\n",
      "180 -> 0.835\n",
      "190 -> 0.835\n",
      "200 -> 0.836\n",
      "\n",
      "min_samples_leaf: 3\n",
      "10 -> 0.818\n",
      "30 -> 0.831\n",
      "50 -> 0.836\n",
      "70 -> 0.838\n",
      "90 -> 0.840\n",
      "110 -> 0.840\n",
      "130 -> 0.840\n",
      "150 -> 0.840\n",
      "170 -> 0.841\n",
      "190 -> 0.841\n",
      "\n",
      "min_samples_leaf: 5\n",
      "10 -> 0.826\n",
      "30 -> 0.830\n",
      "50 -> 0.835\n",
      "70 -> 0.839\n",
      "90 -> 0.840\n",
      "110 -> 0.840\n",
      "130 -> 0.841\n",
      "150 -> 0.841\n",
      "170 -> 0.843\n",
      "190 -> 0.842\n",
      "\n",
      "min_samples_leaf: 10\n",
      "10 -> 0.827\n",
      "30 -> 0.834\n",
      "50 -> 0.836\n",
      "70 -> 0.839\n",
      "90 -> 0.840\n",
      "110 -> 0.839\n",
      "130 -> 0.839\n",
      "150 -> 0.839\n",
      "170 -> 0.840\n",
      "190 -> 0.840\n",
      "\n",
      "train auc 0.9406080013975749\n",
      "val auc 0.8425505877699353\n",
      "[07:30:31] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.75770\tval-auc:0.75323\n",
      "[10]\ttrain-auc:0.80131\tval-auc:0.78536\n",
      "[20]\ttrain-auc:0.82475\tval-auc:0.80505\n",
      "[30]\ttrain-auc:0.83645\tval-auc:0.81614\n",
      "[40]\ttrain-auc:0.84447\tval-auc:0.82092\n",
      "[50]\ttrain-auc:0.85117\tval-auc:0.82796\n",
      "[60]\ttrain-auc:0.85473\tval-auc:0.83059\n",
      "[70]\ttrain-auc:0.85862\tval-auc:0.83141\n",
      "[80]\ttrain-auc:0.86163\tval-auc:0.83380\n",
      "[90]\ttrain-auc:0.86352\tval-auc:0.83507\n",
      "[100]\ttrain-auc:0.86613\tval-auc:0.83747\n",
      "[110]\ttrain-auc:0.86826\tval-auc:0.83894\n",
      "[120]\ttrain-auc:0.86940\tval-auc:0.84001\n",
      "[130]\ttrain-auc:0.87067\tval-auc:0.84081\n",
      "[140]\ttrain-auc:0.87180\tval-auc:0.84206\n",
      "[150]\ttrain-auc:0.87268\tval-auc:0.84291\n",
      "[160]\ttrain-auc:0.87358\tval-auc:0.84396\n",
      "[170]\ttrain-auc:0.87428\tval-auc:0.84449\n",
      "[180]\ttrain-auc:0.87507\tval-auc:0.84519\n",
      "[190]\ttrain-auc:0.87574\tval-auc:0.84573\n",
      "[200]\ttrain-auc:0.87623\tval-auc:0.84578\n",
      "[210]\ttrain-auc:0.87688\tval-auc:0.84640\n",
      "[220]\ttrain-auc:0.87748\tval-auc:0.84648\n",
      "[230]\ttrain-auc:0.87806\tval-auc:0.84655\n",
      "[240]\ttrain-auc:0.87865\tval-auc:0.84667\n",
      "[250]\ttrain-auc:0.87906\tval-auc:0.84681\n",
      "[260]\ttrain-auc:0.87957\tval-auc:0.84703\n",
      "[270]\ttrain-auc:0.88011\tval-auc:0.84705\n",
      "[280]\ttrain-auc:0.88076\tval-auc:0.84662\n",
      "[290]\ttrain-auc:0.88131\tval-auc:0.84674\n",
      "[300]\ttrain-auc:0.88174\tval-auc:0.84652\n",
      "[310]\ttrain-auc:0.88208\tval-auc:0.84602\n",
      "[320]\ttrain-auc:0.88265\tval-auc:0.84617\n",
      "[330]\ttrain-auc:0.88291\tval-auc:0.84623\n",
      "[340]\ttrain-auc:0.88353\tval-auc:0.84620\n",
      "[350]\ttrain-auc:0.88402\tval-auc:0.84640\n",
      "[360]\ttrain-auc:0.88433\tval-auc:0.84637\n",
      "[370]\ttrain-auc:0.88477\tval-auc:0.84632\n",
      "[380]\ttrain-auc:0.88518\tval-auc:0.84609\n",
      "[390]\ttrain-auc:0.88558\tval-auc:0.84593\n",
      "[400]\ttrain-auc:0.88605\tval-auc:0.84605\n",
      "[410]\ttrain-auc:0.88635\tval-auc:0.84579\n",
      "[420]\ttrain-auc:0.88681\tval-auc:0.84533\n",
      "[430]\ttrain-auc:0.88728\tval-auc:0.84583\n",
      "[440]\ttrain-auc:0.88763\tval-auc:0.84547\n",
      "[450]\ttrain-auc:0.88794\tval-auc:0.84571\n",
      "[460]\ttrain-auc:0.88836\tval-auc:0.84589\n",
      "[470]\ttrain-auc:0.88873\tval-auc:0.84582\n",
      "[480]\ttrain-auc:0.88902\tval-auc:0.84590\n",
      "[490]\ttrain-auc:0.88936\tval-auc:0.84598\n",
      "[499]\ttrain-auc:0.88962\tval-auc:0.84600\n",
      "[07:30:34] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8438721476469956"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1- Dataset preparation\n",
    "#spliting dataset using scikit-learn\n",
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=11)\n",
    "df_train, df_val = train_test_split(df_train_full, test_size=0.25, random_state=11)\n",
    "\n",
    "# checking sizes of our splited data\n",
    "len(df_train), len(df_val), len(df_test)\n",
    "\n",
    "#catching our target variables(status)\n",
    "y_train = (df_train.status == 'default').values\n",
    "y_val = (df_val.status == 'default').values\n",
    "\n",
    "#delete target variable from the training and validation sets\n",
    "del df_train['status']\n",
    "del df_val['status']\n",
    "\n",
    "# replace missing values(NAN that we add before for missing values) with zero\n",
    "df_train = df_train.fillna(0)\n",
    "df_val = df_val.fillna(0)\n",
    "\n",
    "# convert dataframe to a list of dictionaries to be able to pass them to DictVectorizer to apply one-hot encoding.\n",
    "dict_train = df_train.to_dict('records')\n",
    "dict_val = df_val.to_dict('records')\n",
    "\n",
    "# applying one-hot encoding\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "x_train = dv.fit_transform(dict_train)\n",
    "x_val = dv.transform(dict_val)\n",
    "\n",
    "# 2- training model (Decision Tree: is a set of if-else statement)\n",
    "dt = DecisionTreeClassifier(max_depth=2) #by limiting the tree depth, we make our model be able to more generalize.\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "# 3- evaluating performance of the model (using AUC)\n",
    "\n",
    "#we need scores(probability) , not hard predictions.\n",
    "# we have overfitting for the validation set, so we need to make the model less powerful\n",
    "# to improve the model's ability to generalize \n",
    "y_pred = dt.predict_proba(x_train)[:,1]\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('train auc', auc)\n",
    "\n",
    "y_pred = dt.predict_proba(x_val)[:,1]\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "print('val auc', auc)\n",
    "\n",
    "\n",
    "# To visualize the tree we just learned\n",
    "# tree_text = export_text(dt, feature_names=dv.feature_names_)\n",
    "# print(tree_text)\n",
    "\n",
    "# measuring the degree of impurity, using misclassification rate(how many observations in a group don't belong to the majority class).\n",
    "#how decision tree algorithm work:\n",
    "# spliting data related to specific feature and try all thresholds to find the one with the least impurties \n",
    "# when splitting the data, until there is no impurties found it stops (read more on stopping criteria)\n",
    "\n",
    "# 4- parameter tuning for decision tree (the most important are => max_depth and min_leaf_size)\n",
    "# getting the best depth values for the decision tree, which is (4,5,6)\n",
    "for depth in [1, 2, 3, 4, 5, 6, 10, 15, 20, None]:\n",
    "    dt = DecisionTreeClassifier(max_depth=depth)\n",
    "    dt.fit(x_train, y_train)\n",
    "    y_pred = dt.predict_proba(x_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    print('%4s -> %.3f' % (depth, auc))\n",
    "\n",
    "# getting the best min_sample_leaf value for our decision tree\n",
    "for m in [4, 5, 6]:\n",
    "    print('depth: %s' % m)\n",
    "    \n",
    "    for s in [1, 5, 10, 15, 20, 50, 100, 200]:\n",
    "        dt = DecisionTreeClassifier(max_depth=m, min_samples_leaf=s)\n",
    "        dt.fit(x_train, y_train)\n",
    "        y_pred = dt.predict_proba(x_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        print('%s -> %.3f' % (s, auc))\n",
    "    \n",
    "    print()\n",
    "\n",
    "# best parameters are max_depth = 6 and min_sample_leaf=20 (the value we use for min_leaf_size influences the best value of max_depth.)\n",
    "# 5- train model on the tunned parameters\n",
    "dt = DecisionTreeClassifier(max_depth=6, min_samples_leaf=20) \n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "# using the tunned parameters on training dataset we get 84% accuracy, which is better than 70%\n",
    "y_pred = dt.predict_proba(x_train)[:,1]\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('train auc', auc)\n",
    "\n",
    "# using the tunned paramters on validation dataset we get 80% accuracy, which is better than 68%\n",
    "y_pred = dt.predict_proba(x_val)[:,1]\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "print('val auc', auc)\n",
    "\n",
    "# 6- Random forest (ensemble learning = combineing multiple decision trees together to make the model achieve better predictive performance)\n",
    "\n",
    "# For this to work, the models need to be different. If we train the same decision tree model\n",
    "# ten times, they will all predict the same output, so its not useful at all.\n",
    "\n",
    "# The easiest way to have different models is to train each tree on a different subset of features.\n",
    "\n",
    "#To train random forest, we can do this:\n",
    "# Train N independent decision tree models.80\n",
    "# For each model, select a random subset of features, and use only them for training.\n",
    "# When predicting, combine the output of N models into one.\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10, random_state=3) # n_estimators means the number of decision trees in the random forest\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf.predict_proba(x_val)[:, 1]\n",
    "roc_auc_score(y_val, y_pred)\n",
    "\n",
    "#iterating over the best possible value of number of decision trees(n_estimators) related to the randomForest\n",
    "aucs = []\n",
    "\n",
    "for i in range(10, 201, 10):\n",
    "    rf = RandomForestClassifier(n_estimators=i, random_state=3) \n",
    "    rf.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = rf.predict_proba(x_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    print('%s -> %.3f' % (i, auc))\n",
    "    \n",
    "    aucs.append(auc)\n",
    "\n",
    "plt.plot(range(10, 201, 10), aucs)\n",
    "\n",
    "# 7- parameter tuning for random forst\n",
    "# iterating over the best value for decision tree depth\n",
    "all_aucs = {} \n",
    "\n",
    "for depth in [5, 10, 20]: \n",
    "    print('depth: %s' % depth)\n",
    "    aucs = [] \n",
    "\n",
    "    for i in range(10, 201, 10): \n",
    "        rf = RandomForestClassifier(n_estimators=i, max_depth=depth, random_state=1) \n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred = rf.predict_proba(x_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_pred) \n",
    "        print('%s -> %.3f' % (i, auc)) \n",
    "        aucs.append(auc) \n",
    "\n",
    "    all_aucs[depth] = aucs \n",
    "    print()\n",
    "    \n",
    "#plotting aucs related to max_depth of the decision trees values, which is (10)\n",
    "# num_trees = list(range(10, 201, 10))\n",
    "# plt.plot(num_trees, all_aucs[5], label='depth=5')\n",
    "# plt.plot(num_trees, all_aucs[10], color=\"green\",label='depth=10')\n",
    "# plt.plot(num_trees, all_aucs[20], label='depth=20')\n",
    "# plt.legend()\n",
    "\n",
    "# iterating over the best value for min_sample_leaf based on the max depth(10) we get in the last step\n",
    "all_aucs = {}\n",
    "\n",
    "for m in [3, 5, 10]:\n",
    "    print('min_samples_leaf: %s' % m)\n",
    "    aucs = []\n",
    "\n",
    "    for i in range(10, 201, 20):\n",
    "        rf = RandomForestClassifier(n_estimators=i, max_depth=10, min_samples_leaf=m, random_state=1)\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred = rf.predict_proba(x_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        print('%s -> %.3f' % (i, auc))\n",
    "        aucs.append(auc)\n",
    "        \n",
    "    all_aucs[m] = aucs\n",
    "    print()\n",
    "    \n",
    "#min_sample_leaf is (5) with max depth 0f (10)\n",
    "num_trees = list(range(10, 201, 20))\n",
    "plt.plot(num_trees, all_aucs[3], label='min_samples_leaf=3')\n",
    "plt.plot(num_trees, all_aucs[5], label='min_samples_leaf=5')\n",
    "plt.plot(num_trees, all_aucs[10], label='min_samples_leaf=10')\n",
    "plt.legend()\n",
    "\n",
    "# 8- training the final model of random forest on the tuned parameters\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_leaf=5, random_state=1)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# we get 94% on training set, which is better than 84% on a single decision tree\n",
    "y_pred = rf.predict_proba(x_train)[:,1]\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('train auc', auc)\n",
    "\n",
    "# we get 84% on validation set, which is better than 80% on a single decision tree\n",
    "y_pred = rf.predict_proba(x_val)[:,1]\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "print('val auc', auc)\n",
    "\n",
    "\n",
    "# 9- using another approach ot train our model(XGBoost)\n",
    "# Gradient boosting: we can train models sequentially, as each next model tries to fix errors from the previous one (Using another approach to traing our model)\n",
    "#there are many good implementations of the gradient boosting model from scikit-learn, as XGBoost, LightGBM and CatBoost\n",
    "# the most popular one is \"XGBoost\"(Extreme Gradient Boosting)\n",
    "\n",
    "#putting training and validation set in a DMatrix to be able to use XGBoost on the sets.\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train, feature_names=dv.feature_names_)\n",
    "dval = xgb.DMatrix(x_val, label=y_val, feature_names=dv.feature_names_)\n",
    "\n",
    "# specificying xgboost default parameters for training\n",
    "xgb_params = {\n",
    "    'eta': 0.05, # learning rate (determines the weight of the correction)\n",
    "    'max_depth': 3, #tree depth\n",
    "    'min_child_weight': 50, #equal to min_samples_leaf(The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf)\n",
    "    'objective': 'binary:logistic', # type of our model which is binary classification\n",
    "    'eval_metric': 'auc', # evaluation metric\n",
    "    'nthread': 4, #set it to the number of cores your computer has.\n",
    "    'seed': 1, #to make result repreduciable\n",
    "    'silent': 1 # the verbosity of the output, when set to \"1\", it'll output only warnings\n",
    "}\n",
    "\n",
    "# monitoring model performance (watchlist)\n",
    "# training an XGBoost model is simpler when we can see how it's performance changes when the number of trees grows.\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "# our model has the effect of over fitting: it becomes more and more complex until it simply memorizes the entire training set\n",
    "# on the validation set it improves then it declines due to overfitting.\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=500, #increase the number of trees if the \"eta\" is small\n",
    "                 evals=watchlist, verbose_eval=10) #num_boost_round is the number of trees, verbose_eval is the number we jump with\n",
    "#get predictions of the validation set\n",
    "y_pred = model.predict(dval)\n",
    "y_pred[:10]\n",
    "\n",
    "#evaluate accuracy of XGBoost on validation set, which is 82% that is lower than our prediction using random forest 84%\n",
    "#after tunning the parameters(max_depth=3, min_child_weight=50): we get 84.7% on validation set\n",
    "#When eta is 0.05 , AUC grows slower, but peaks at a higher value. For a smaller learning\n",
    "#rate, it takes more trees to reach the peak, but we could achieve better performance.\n",
    "roc_auc_score(y_val, y_pred)\n",
    "\n",
    "#we get 84.7% after tuning parameters using XGBoost, which is 0.7% better than random forest.\n",
    "\n",
    "#10- Testing the final model\n",
    "#we will use the validation data as a part of the training data as we get our purpose from it, by tunning our parameters well.\n",
    "#create the traget variable\n",
    "y_train = (df_train_full.status == 'default').values\n",
    "y_test = (df_test.status == 'default').values\n",
    "\n",
    "#remove target variable\n",
    "del df_train_full['status']\n",
    "del df_test['status']\n",
    "\n",
    "#we convert dataframes into lists of dictionaries, and then use one-hot encoding to get the feature matrices.\n",
    "dict_train = df_train_full.fillna(0).to_dict('records')\n",
    "dict_test = df_test.fillna(0).to_dict('records')\n",
    "dv = DictVectorizer(sparse=False)\n",
    "x_train = dv.fit_transform(dict_train)\n",
    "x_test = dv.transform(dict_test)\n",
    "\n",
    "#Finally, train the XGBoost model using this data and the optimal parameters we determined previously.\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train, feature_names=dv.feature_names_)\n",
    "dtest = xgb.DMatrix(x_test, label=y_test, feature_names=dv.feature_names_)\n",
    "\n",
    "num_trees = 270\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=num_trees)\n",
    "\n",
    "#evaluating the performance of the test set\n",
    "y_pred_xgb = model.predict(dtest)\n",
    "roc_auc_score(y_test, y_pred_xgb)\n",
    "# it gives 84.3% which is better than the validation of the random forest with 0.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
